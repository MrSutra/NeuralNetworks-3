{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta 2.2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cFVlkYjqPivE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. *Question Answering*"
      ]
    },
    {
      "metadata": {
        "id": "7yIQMCskPivF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las redes neuronales recurrentes hoy en día han sido aplicadas a varios problemas que involucra dependencia temporal de los datos de entrada, en textos por lo común, tal como los modelos *sequence to sequence* de traducción, resumir textos, formular hipótesis de un extracto o, como veremos en esta actividad, generar respuesta en base a alguna pregunta. En imágenes también han sido aplicadas, ya sea a procesamiento de videos u a otro problema en que las imágenes tienen dependencia temporal unas con otras.\n",
        "\n",
        "Para ésta actividad trabajaremos el dataset de __[SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/)__  (The Stanford Question Answering Dataset), los datos se los entregamos en formato *csv*, sin ningún preprocesamiento, para que sea mas fácil la lectura. La tarea como ya se comentó consiste en predecir una respuesta (secuencia de palabras) que contesten una pregunta también en forma de secuencia de palabras, con un enfoque *encoder-decoder* con módulos de antención.\n",
        "\n",
        "\n",
        "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/07/20/sockeye_1.gif\" title=\"Attention\" width=\"65%\" style=\"float: right;\"/>\n",
        "\n",
        "\n",
        "<img src=\"http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png\" title=\"Attention\" width=\"35%\" style=\"float: left;\"/>\n",
        "\n",
        "\n",
        "\n",
        "Los módulos de antención [[6]](#refs) son una variación a la arquitectura *encoder-decoder* en donde se agrega que para cada instante de tiempo de la **decodificación** $T'$ hay una combinación lineal del vector de codificación en todos los instantes tiempo $T$, ésto es para que en cada instante de tiempo de la decodificación se ponga atención a cierta información en toda la secuencia de entrada. \n",
        "\n",
        "\n",
        "$$\n",
        "y_{T'} = \\sum_{t}^{T} \\alpha_{T',t} \\cdot h_t^{codificacion}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "aLcK__JzPivF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJwZAul-PivJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> a) Carge los datos y descríbalos ¿Cuántos ejemplos se tienen para entrenar y para predecir?\n",
        "\n",
        "Cargamos los datos. Éstos vienen separados en dos datasets, uno para training y otro para testing. "
      ]
    },
    {
      "metadata": {
        "id": "CAbdMg15PivJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "46b0902e-e7d8-42e1-8e2b-6c229ab41e50"
      },
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('drive/Colab-Notebooks/train_Q-A.csv')\n",
        "df_train.dropna(inplace=True)\n",
        "df_test = pd.read_csv('drive/Colab-Notebooks/test_Q.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  \\\n",
              "0  56be85543aeaaa14008c9063   \n",
              "1  56be85543aeaaa14008c9065   \n",
              "2  56be85543aeaaa14008c9066   \n",
              "3  56bf6b0f3aeaaa14008c9601   \n",
              "4  56bf6b0f3aeaaa14008c9602   \n",
              "\n",
              "                                            question               answer  \n",
              "0           When did Beyonce start becoming popular?    in the late 1990s  \n",
              "1  What areas did Beyonce compete in when she was...  singing and dancing  \n",
              "2  When did Beyonce leave Destiny's Child and bec...                 2003  \n",
              "3      In what city and state did Beyonce  grow up?        Houston, Texas  \n",
              "4         In which decade did Beyonce become famous?           late 1990s  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "UlL_ljy-NG59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El conjunto de datos de entrenamiento contiene tres columnas: id, **question** y **answer**. Cada entra en el dataset contiene una pregunta en conjunto con su respuesta. Estas están escritas en inglés, y por lo que se puede ver continen letras, números y caracteres de puntuación."
      ]
    },
    {
      "metadata": {
        "id": "z_PgfdLRPivO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2effdde9-e117-4a32-cd19-9623593c32bf"
      },
      "cell_type": "code",
      "source": [
        "print(\"Cantidad de ejemplos de entrenamiento: \", df_train.shape[0])\n",
        "print(\"Cantidad de ejemplos de prueba: \", df_test.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de ejemplos de entrenamiento:  86821\n",
            "Cantidad de ejemplos de prueba:  11873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MTwhb3QpN8ok",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La cantidad de datos de entrenamiento es 86.821 y los datos de prueba son 11.873."
      ]
    },
    {
      "metadata": {
        "id": "nkDUv4TuPivR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bd292367-1461-4fc6-9915-de16d92872e2"
      },
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>86821</td>\n",
              "      <td>86821</td>\n",
              "      <td>86821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>86821</td>\n",
              "      <td>86769</td>\n",
              "      <td>64763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>5735c421dc94161900571ffc</td>\n",
              "      <td>What is the national bird of Bermuda?</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id                               question answer\n",
              "count                      86821                                  86821  86821\n",
              "unique                     86821                                  86769  64763\n",
              "top     5735c421dc94161900571ffc  What is the national bird of Bermuda?  three\n",
              "freq                           1                                      2    231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "P1Zd3Rr5OM9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se puede ver que hay tanto preguntas como respuestas repetidas, con una mayor cantida de respuestas repetidas.. Debido a que algunas de estas son cortas (dos palabras) es probable que se repitan en más de una ocación. "
      ]
    },
    {
      "metadata": {
        "id": "BzMl9wq5PivU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "dff123fe-f39e-47f9-a93b-73333106ff21"
      },
      "cell_type": "code",
      "source": [
        "df_test.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11873</td>\n",
              "      <td>11873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>11873</td>\n",
              "      <td>11864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>5a67978ef038b7001ab0c308</td>\n",
              "      <td>What is the CJEU's duty?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id                  question\n",
              "count                      11873                     11873\n",
              "unique                     11873                     11864\n",
              "top     5a67978ef038b7001ab0c308  What is the CJEU's duty?\n",
              "freq                           1                         2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "XIXxzj5zPivX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> b) Realice un preprocesamiento simple a los textos de entrada (preguntas) *tokenizandolos* y pasando a minúsculas para evitar ambiguedad, si desea agregar algun preprocesamiento éxtra ésto se verá reflajado en su nota. A los textos de salida (respuestas) no realice ningún preprocesamiento mas que *tokenizar*, puesto que para la evaluación se solicita retornar los textos en su forma natural. Comente lo realizado.\n",
        "\n",
        "Se hace un preprocesamiento de dos partes. En la primera se pasarán las preguntas a minúsculas y luego se *tokenizarán*. Cabe destacar que la *tokenización* utilizada elimina los signos de interrogación y de puntuación, no eliminando los números que aportan información tanto en preguntas como en respuestas.\n"
      ]
    },
    {
      "metadata": {
        "id": "GPPEilLAPivY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "91584d1b-eaac-445e-c0a3-e051d7bb8e8c"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "#preprocesamiento textos de entrada\n",
        "train_questions = [tokenizer.tokenize(sentence.lower()) for sentence in df_train[\"question\"]]\n",
        "test_questions = [word_tokenize(sentence.lower()) for sentence in df_test[\"question\"]]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WMjHPqk4Piva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7fd4bf05-6769-4bb2-f409-a25b731eb8c3"
      },
      "cell_type": "code",
      "source": [
        "print(train_questions[7])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['who', 'managed', 'the', 'destiny', 's', 'child', 'group']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AjLDb_qZPivd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "192be425-d6fb-4450-d885-b013ca95e81f"
      },
      "cell_type": "code",
      "source": [
        "df_train[\"question\"][:10]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             When did Beyonce start becoming popular?\n",
              "1    What areas did Beyonce compete in when she was...\n",
              "2    When did Beyonce leave Destiny's Child and bec...\n",
              "3        In what city and state did Beyonce  grow up? \n",
              "4           In which decade did Beyonce become famous?\n",
              "5           In what R&B group was she the lead singer?\n",
              "6        What album made her a worldwide known artist?\n",
              "7               Who managed the Destiny's Child group?\n",
              "8                       When did Beyoncé rise to fame?\n",
              "9       What role did Beyoncé have in Destiny's Child?\n",
              "Name: question, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "Sveeb54IU4aX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "De igual manera se *tokenizan* las palabras de las respuestas."
      ]
    },
    {
      "metadata": {
        "id": "zMx2AAr_Pivh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_answers = [word_tokenize(sentence) for sentence in df_train[\"answer\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NW1CP251VAJU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La segunda parte del procesamiento consiste en realizar lemmatización a las preguntas. Esto hará que las palabras sean reemplazadas por su raiz léxica actuando como normalizador de los datos de entrada. Así se podrá reducir el vocabulario y se evitará tener muchas palabras con el mismo significado, pero diferente forma (como pasa con las conjugaciones de los verbos)"
      ]
    },
    {
      "metadata": {
        "id": "UYHOMXeQPivi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d65d4264-7585-4a79-b96f-0c7a33ba1ffc"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# lemmas para train y test\n",
        "for q in range(len(train_questions)):\n",
        "    train_questions[q] = [WordNetLemmatizer().lemmatize(w) for w in train_questions[q]]\n",
        "for q in range(len(test_questions)):\n",
        "    test_questions[q] = [WordNetLemmatizer().lemmatize(w) for w in test_questions[q]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hztRaLnvPivl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "046c7923-a76f-46e7-c305-4553b9e6d662"
      },
      "cell_type": "code",
      "source": [
        "train_questions[3:9]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['in', 'what', 'city', 'and', 'state', 'did', 'beyonce', 'grow', 'up'],\n",
              " ['in', 'which', 'decade', 'did', 'beyonce', 'become', 'famous'],\n",
              " ['in', 'what', 'r', 'b', 'group', 'wa', 'she', 'the', 'lead', 'singer'],\n",
              " ['what', 'album', 'made', 'her', 'a', 'worldwide', 'known', 'artist'],\n",
              " ['who', 'managed', 'the', 'destiny', 's', 'child', 'group'],\n",
              " ['when', 'did', 'beyoncé', 'rise', 'to', 'fame']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "crQp2gzPPivs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> c) Cree un vocabulario para codificar las palabras en las respuestas a generar. Repita el procedimiento para las preguntas. Agrege un símbolo que signifique el fin de la respuesta a generar, así para tener un criterio de cuando una respuesta, valga la redundancia, está efectivamente *respondida* ¿Cuántas palabras tiene el vocabulario de las respuestas y de las preguntas? ¿Ésto podría ser un problema al momento de entrenar la red para que predizca de entre todas ellas?"
      ]
    },
    {
      "metadata": {
        "id": "HTRuX5OoV8mD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se generarán dos clases de diccionarios: uno que utiliza las palabras como *keys* y los id como *values*, y otro que es el inverso a este.\n"
      ]
    },
    {
      "metadata": {
        "id": "upfK7ljYPivs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00051fcc-94e7-44de-c51d-396de7eed417"
      },
      "cell_type": "code",
      "source": [
        "vocab_answer = set()\n",
        "for sentence in train_answers:\n",
        "    for word in sentence:\n",
        "        vocab_answer.add(word)\n",
        "vocab_answer = [\"#end\"]+ list(vocab_answer)\n",
        "print('posibles palabras para respuestas :', len(vocab_answer))\n",
        "vocabA_indices = {c: i for i, c in enumerate(vocab_answer)}\n",
        "indices_vocabA = {i: c for i, c in enumerate(vocab_answer)}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "posibles palabras para respuestas : 47423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aBtvc0sKZ9bo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El tamaño total del vocabulario de las respuestas es de 47.423 términos."
      ]
    },
    {
      "metadata": {
        "id": "V14yVrORPivw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "453fcc07-34fd-48ff-9fd2-8bc47de6b0b9"
      },
      "cell_type": "code",
      "source": [
        "#sameforquestions\n",
        "vocab_question = set()\n",
        "for sentence in train_questions+test_questions:\n",
        "    for word in sentence:\n",
        "        vocab_question.add(word)\n",
        "vocab_question = list(vocab_question)\n",
        "print('posibles palabras para preguntas :', len(vocab_question))\n",
        "vocabQ_indices = {c: i for i, c in enumerate(vocab_question)}\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "posibles palabras para preguntas : 35201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iTM7LhHZPiv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "d) Codifique los tokens (palabras) de cada texto que utilizará."
      ]
    },
    {
      "metadata": {
        "id": "5bDUnDBtPiv0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#input and output to onehotvector\n",
        "X_answers = [[vocabA_indices[palabra] for palabra in sentence] for sentence in train_answers]\n",
        "Xtrain_question = [[vocabQ_indices[word] for word in sentence] for sentence in train_questions]\n",
        "Xtest_question = [[vocabQ_indices[word] for word in sentence] for sentence in test_questions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nk1wrg1lPiv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b61d5a83-e96a-421b-893f-210a69770868"
      },
      "cell_type": "code",
      "source": [
        "print(len(Xtrain_question))\n",
        "len(Xtest_question)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "4mGxDM8dPiv6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego de ésto realice un padding a ambas secuencias, entrada y salida de entrenamiento y a la entrada del conjunto de pruebas. Comente sobre las dimensionalidades finales de los conjuntos de entrenamiento y de prueba."
      ]
    },
    {
      "metadata": {
        "id": "xj0YuTIJPiv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "317d6d48-5f47-4a5b-99f6-9e2447a5f71e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "max_input_lenght = np.max(list(map(len,train_questions)))\n",
        "max_output_lenght = np.max(list(map(len,train_answers)))+1\n",
        "print(\"Max largo pregunta: {}\\nMax largo respuesta: {}\".format(max_input_lenght, max_output_lenght))\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "Xtrain_question = sequence.pad_sequences(Xtrain_question,maxlen=max_input_lenght,padding='post',value=0)\n",
        "Xtest_question = sequence.pad_sequences(Xtest_question,maxlen=max_input_lenght,padding='post',value=0)\n",
        "X_answers = sequence.pad_sequences(X_answers,maxlen=max_output_lenght,padding='post',value=vocabA_indices[\"#end\"])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max largo pregunta: 40\n",
            "Max largo respuesta: 47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jhOSK4lvPiv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c3371e9e-108b-44e0-cd60-eda6f2599d7f"
      },
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones Xtrain: {}\".format(Xtrain_question.shape))\n",
        "print(\"Dimensiones Xtest: {}\".format(Xtest_question.shape))\n",
        "print(\"Dimensiones Output: {}\".format(X_answers.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensiones Xtrain: (86821, 40)\n",
            "Dimensiones Xtest: (11873, 40)\n",
            "Dimensiones Output: (86821, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3qDRPYRjPiwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5042f08b-0a96-42d5-ef41-1dc52d6b08bc"
      },
      "cell_type": "code",
      "source": [
        "X_answers  = X_answers.reshape(X_answers.shape[0],X_answers.shape[1],1)\n",
        "print(\"Nueva dimensión salida: {}\".format(X_answers.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nueva dimensión salida: (86821, 47, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tl5ln3VgPiwI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "e) Defina el modelo encoder-decoder con los módulos de atención."
      ]
    },
    {
      "metadata": {
        "id": "ldMW1CscPiwI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Encoder-Decoder modelo\n",
        "from keras.layers import Input,RepeatVector,TimeDistributed,Dense,Embedding,Flatten,Activation,Permute,Lambda, CuDNNLSTM, LSTM,CuDNNGRU\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "lenght_output = max_output_lenght\n",
        "hidden_dim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5O9eY7PPiwL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Defina el encoder y las compuertas que utilizará: CuDNNGRU,CuDNNLSTM, RNN u otra. Puede utilizar redes bidireccionales en el encoder ¿Esto mejora el resultado?"
      ]
    },
    {
      "metadata": {
        "id": "Lr7zLtaYPiwM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# probar con otras compuertas\n",
        "embedding_vector = 64 \n",
        "encoder_input = Input(shape=(max_input_lenght,))\n",
        "embedded = Embedding(input_dim=len(vocabQ_indices)+1,output_dim = embedding_vector,input_length=max_input_lenght)(encoder_input)\n",
        "encoder = CuDNNGRU(hidden_dim, return_sequences=True)(embedded)\n",
        "\n",
        "#encoder = LSTM(hidden_dim, return_sequences=True)(embedded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Rp4C0-2PiwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d704bfa-993a-46c3-8084-4330f2d972a9"
      },
      "cell_type": "code",
      "source": [
        "max_output_lenght"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "uUAOVCnMPiwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Defina la atención $\\alpha$ que se calculará sobre cada instante de tiempo $T$ computándo su atención en cada instante de tiempo de la decodificación $T'$."
      ]
    },
    {
      "metadata": {
        "id": "pAM7hfCZPiwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compute T' importance for each step T\n",
        "attention = TimeDistributed(Dense(max_output_lenght, activation='tanh'))(encoder)\n",
        "#softmax a las antenciones sobre todo T\n",
        "attention = Permute([2, 1])(attention)\n",
        "attention = Activation('softmax')(attention) \n",
        "attention = Permute([2, 1])(attention)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rXKGRNVUPiwV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aplique la atención sobre el encoder y genere las salidas correspondientes."
      ]
    },
    {
      "metadata": {
        "id": "JruzQOE9PiwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply the attention to encoder\n",
        "def attention_multiply(vects):\n",
        "    encoder, attention = vects\n",
        "    return K.batch_dot(attention,encoder, axes=1)\n",
        "sent_representation = Lambda(attention_multiply)([encoder, attention])\n",
        "\n",
        "#decoder = LSTM(hidden_dim, return_sequences=True)(sent_representation)\n",
        "decoder = CuDNNGRU(hidden_dim, return_sequences=True)(sent_representation)\n",
        "probabilities = TimeDistributed(Dense(len(vocab_answer), activation=\"softmax\"))(decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2K4f4aOPiwa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Defina el modelo y descríbalo adecuadamente."
      ]
    },
    {
      "metadata": {
        "id": "F-VN7pFvPiwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "710e5aa8-476d-47bf-f026-b84f514a1ad2"
      },
      "cell_type": "code",
      "source": [
        "model = Model(encoder_input,probabilities)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 40)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 40, 64)       2252928     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)          (None, 40, 128)      74496       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 40, 47)       6063        cu_dnngru_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 47, 40)       0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 47, 40)       0           permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 40, 47)       0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 47, 128)      0           cu_dnngru_1[0][0]                \n",
            "                                                                 permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_2 (CuDNNGRU)          (None, 47, 128)      99072       lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 47, 47423)    6117567     cu_dnngru_2[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 8,550,126\n",
            "Trainable params: 8,550,126\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MmMbEINEKnRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bdedce50-b4bb-408d-b3b5-4493c0d9985d"
      },
      "cell_type": "code",
      "source": [
        "!pip install pydot"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.2.4)\r\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.2.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ekIZ4yY1Piwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "528f8511-9f14-416c-de3c-07fab3896098"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG, Image\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_p2.png', show_shapes=True)\n",
        "Image(filename='model_p2.png')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7b1f1f5944da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_p2.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_p2.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
            "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eWRT2gVrPiwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "f) Entrene el modelo por 10 epochs con el tamaño de batch que estime conveniente. Para ésto deberá redimensionar la salida para que tenga 3 dimensiones debido a la recurrencia."
      ]
    },
    {
      "metadata": {
        "id": "0tA9fWmLPiwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "eb41f481-0858-41fe-9844-f25c22b0e873"
      },
      "cell_type": "code",
      "source": [
        "#X_answers = X_answers.reshape(X_answers.shape[0],X_answers.shape[1],1)\n",
        "#X_answers.shape\n",
        "model.fit(Xtrain_question,X_answers,epochs=10,batch_size=128,validation_split=0.2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 69456 samples, validate on 17365 samples\n",
            "Epoch 1/10\n",
            "69456/69456 [==============================] - 355s 5ms/step - loss: 1.2216 - val_loss: 0.7922\n",
            "Epoch 2/10\n",
            "69456/69456 [==============================] - 353s 5ms/step - loss: 0.6964 - val_loss: 0.8001\n",
            "Epoch 3/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6830 - val_loss: 0.8074\n",
            "Epoch 4/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6744 - val_loss: 0.8088\n",
            "Epoch 5/10\n",
            "69456/69456 [==============================] - 351s 5ms/step - loss: 0.6655 - val_loss: 0.8113\n",
            "Epoch 6/10\n",
            "69456/69456 [==============================] - 351s 5ms/step - loss: 0.6563 - val_loss: 0.8180\n",
            "Epoch 7/10\n",
            "69456/69456 [==============================] - 351s 5ms/step - loss: 0.6480 - val_loss: 0.8328\n",
            "Epoch 8/10\n",
            "69456/69456 [==============================] - 351s 5ms/step - loss: 0.6400 - val_loss: 0.8295\n",
            "Epoch 9/10\n",
            "69456/69456 [==============================] - 351s 5ms/step - loss: 0.6316 - val_loss: 0.8378\n",
            "Epoch 10/10\n",
            "69456/69456 [==============================] - 350s 5ms/step - loss: 0.6223 - val_loss: 0.8474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6aa966400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "LNLtZuNQPiwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"QA.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "muKj5_HsarQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0dd55322-3ea7-4df8-cc33-d6b7eeb6653c"
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#files.download( \"QA.h5\" ) \n",
        "!ls"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QA.h5  sample_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e_o-rxokcyTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vr0owB0CdPcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"drive/QA.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p9nwHJkGmCIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('drive/QA.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ekBcU751ZgBY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> g) Muestre ejemplos de la predicción del modelo, para ésto genere una función que prediga a través de la distribución de probabilidad de la salida, de la forma que estime conveniente, cada palabra en cada instante de tiempo.\n"
      ]
    },
    {
      "metadata": {
        "id": "fjPrGNLDZll2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "b8e79370-9e83-4a69-ed1f-c5c19284e6f8"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def predict_words(model,example,diversity=5):\n",
        "    #predict example\n",
        "    question = list()\n",
        "    preds = model.predict(np.asarray([example]), verbose = 0)[0]\n",
        "    for words in preds:\n",
        "      question.append(random.choice(np.argpartition(words, -diversity)[-diversity:]))\n",
        "    return question\n",
        "    \n",
        "n = 10\n",
        "for i in range(n):\n",
        "    indexs = np.random.randint(0,len(Xtest_question))\n",
        "    example = Xtest_question[indexs]\n",
        "    indexes_answer = predict_words(model,example,5)\n",
        "    question = df_test[\"question\"][indexs]\n",
        "    print(\"Pregunta: \",question)\n",
        "    answer = \"\"\n",
        "    for index in indexes_answer:\n",
        "        if indices_vocabA[index] == \"#end\": # el final de la oracion\n",
        "            continue\n",
        "        else:\n",
        "            answer += indices_vocabA[index]+\" \"\n",
        "    print(\"Respuesta: \", answer)\n",
        "print(\"Los ha predecido todos!\")\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pregunta:  How many societal class divisions were in the plan Kublai rejected?\n",
            "Respuesta:  Haven-style 12-month 867 867 867 Geertz Geertz Zune Geertz Zune Zune 867 calamine Geertz Zune Geertz calamine calamine Geertz Zune calamine Geertz 867 Desperately 867 867 Geertz Geertz Geertz 867 Geertz Desperately 867 867 \n",
            "Pregunta:  What does TFEU article 288 not say?\n",
            "Respuesta:  Zune Square 867 Geertz Geertz Zune Zune Geertz Zune Zune Geertz Zune calamine Zune Geertz Geertz Zune Geertz Geertz Zune calamine calamine Zune calamine Geertz 867 867 Zune calamine calamine Zune calamine calamine Geertz Geertz Zune Zune \n",
            "Pregunta:  Stephen Eildmann cites the oldest known example of civil disobedience in what part of the bible? \n",
            "Respuesta:  whorls 12-month calamine calamine Geertz 867 Geertz calamine Geertz Geertz Geertz calamine Geertz Zune Geertz Geertz calamine Geertz calamine Zune Geertz Zune Geertz Zune calamine calamine Geertz 867 calamine 867 Zune 867 Zune Zune Geertz calamine Zune 867 Zune \n",
            "Pregunta:  On what date did Henry Kissinger negotiate an Israeli troop withdrawal from the Sinai Peninsula?\n",
            "Respuesta:  867 Square calamine Geertz 867 calamine Geertz 867 Geertz Zune 867 calamine Desperately calamine Geertz Geertz calamine Zune calamine Geertz calamine calamine 867 Zune Zune 867 Zune Geertz Geertz calamine 867 867 Desperately Desperately Geertz calamine \n",
            "Pregunta:  What nationality are researchers Richard G. Wilkinson and Kate Pickett?\n",
            "Respuesta:  Marlborough-Blenheim Zune Zune Geertz 867 867 Geertz 867 Geertz calamine calamine Zune Geertz 867 867 867 Geertz Geertz calamine 867 867 calamine 867 calamine calamine calamine Geertz Zune calamine 867 867 Zune calamine calamine calamine 867 Geertz Geertz calamine Zune 867 \n",
            "Pregunta:  How many State of California University campuses are there?\n",
            "Respuesta:  reparations Zune Way Regime Appearances Desperately Appearances Appearances nullius Desperately Desperately Desperately calamine Appearances 867 Desperately 867 Appearances Appearances Desperately Desperately calamine 867 Appearances Desperately calamine calamine calamine 867 Desperately calamine 867 867 Desperately Appearances 867 \n",
            "Pregunta:  What does high levels of inequality do to growth in poor countries?\n",
            "Respuesta:  whorls Zune 867 calamine Zune calamine calamine 867 calamine calamine 867 867 calamine Zune Geertz Geertz Geertz calamine 867 867 867 867 calamine Geertz Zune Geertz 867 Geertz Geertz calamine 867 Geertz 867 calamine 867 \n",
            "Pregunta:  The Hochrhein more than doubles the Rhine's water discharge to what amount?\n",
            "Respuesta:  affricate 12-month Zune calamine 867 Zune 867 calamine calamine Zune Geertz Zune 867 Geertz calamine Geertz Geertz Zune Zune calamine 867 calamine calamine Zune 867 Zune 867 Geertz 867 Geertz calamine Geertz calamine Zune Geertz 867 calamine calamine Geertz Geertz Geertz Zune \n",
            "Pregunta:  What can be used to model tension forces?\n",
            "Respuesta:  Marlborough-Blenheim 12-month Square 867 867 Geertz calamine Geertz calamine calamine calamine Geertz calamine calamine 867 867 Geertz 867 Zune 867 calamine Zune 867 Zune Zune calamine calamine Zune Geertz 867 Zune 867 Geertz calamine Zune Geertz calamine 867 867 867 \n",
            "Pregunta:  What does the Lek change its name to?\n",
            "Respuesta:  whorls 12-month calamine calamine Geertz Zune 867 calamine 867 calamine calamine calamine Zune Zune Zune Geertz 867 calamine Zune Geertz Geertz 867 Zune calamine calamine calamine calamine calamine calamine 867 Zune Zune Geertz calamine calamine Geertz Geertz \n",
            "Los ha predecido todos!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xxNUHNK_QWxC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> h) Evalúe la calidad de su modelo con la métrica del benchmark, para ésto deberá descargar el archivo evaluation script y el dato dev json de la página oficial del dataset: https://rajpurkar.github.io/SQuAD-explorer/ y ejecutarlo de la siguiente manera dentro del Jupyter Notebook\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1u-zxZ0RUTAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44efa58d-b31d-4918-86cc-a6902130c00a"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "contador = 1\n",
        "dic_predictions = {}\n",
        "for example,id_e in zip(Xtest_question,df_test[\"id\"]): #todos los ejemplos\n",
        "    indexes_answer = predict_words(model,example) #predice palabra en cada instante\n",
        "    answer = \"\"\n",
        "    for index in indexes_answer:\n",
        "        if indices_vocabA[index]==\"#end\": # el final de la oracion\n",
        "            continue\n",
        "        else:\n",
        "            answer+=indices_vocabA[index]+\" \"\n",
        "    dic_predictions[id_e] = answer\n",
        "    contador+=1\n",
        "print(\"Los ha predecido todos!\")\n",
        "json_save = json.dumps(dic_predictions)\n",
        "archivo = open(\"predictions\",\"w\")\n",
        "archivo.write(json_save)\n",
        "archivo.close()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los ha predecido todos!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jfg-0uOBQefn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "9c006ab2-de9b-43a2-f020-c805b2027944"
      },
      "cell_type": "code",
      "source": [
        "#evaluar resultados\n",
        "!python evaluate-v2.0.py dev-v2.0.json predictions"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\r\n",
            "  \"exact\": 0.0,\r\n",
            "  \"f1\": 0.0011669235035224271,\r\n",
            "  \"total\": 11873,\r\n",
            "  \"HasAns_exact\": 0.0,\r\n",
            "  \"HasAns_f1\": 0.002337193447591393,\r\n",
            "  \"HasAns_total\": 5928,\r\n",
            "  \"NoAns_exact\": 0.0,\r\n",
            "  \"NoAns_f1\": 0.0,\r\n",
            "  \"NoAns_total\": 5945\r\n",
            "}\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4ZyBfmJtbdTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "gggm"
      ]
    }
  ]
}