{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. *Question Answering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales recurrentes hoy en día han sido aplicadas a varios problemas que involucra dependencia temporal de los datos de entrada, en textos por lo común, tal como los modelos *sequence to sequence* de traducción, resumir textos, formular hipótesis de un extracto o, como veremos en esta actividad, generar respuesta en base a alguna pregunta. En imágenes también han sido aplicadas, ya sea a procesamiento de videos u a otro problema en que las imágenes tienen dependencia temporal unas con otras.\n",
    "\n",
    "Para ésta actividad trabajaremos el dataset de __[SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/)__  (The Stanford Question Answering Dataset), los datos se los entregamos en formato *csv*, sin ningún preprocesamiento, para que sea mas fácil la lectura. La tarea como ya se comentó consiste en predecir una respuesta (secuencia de palabras) que contesten una pregunta también en forma de secuencia de palabras, con un enfoque *encoder-decoder* con módulos de antención.\n",
    "\n",
    "\n",
    "<img src=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/07/20/sockeye_1.gif\" title=\"Attention\" width=\"65%\" style=\"float: right;\"/>\n",
    "\n",
    "\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.16.08-PM.png\" title=\"Attention\" width=\"35%\" style=\"float: left;\"/>\n",
    "\n",
    "\n",
    "\n",
    "Los módulos de antención [[6]](#refs) son una variación a la arquitectura *encoder-decoder* en donde se agrega que para cada instante de tiempo de la **decodificación** $T'$ hay una combinación lineal del vector de codificación en todos los instantes tiempo $T$, ésto es para que en cada instante de tiempo de la decodificación se ponga atención a cierta información en toda la secuencia de entrada. \n",
    "\n",
    "\n",
    "$$\n",
    "y_{T'} = \\sum_{t}^{T} \\alpha_{T',t} \\cdot h_t^{codificacion}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Carge los datos y descríbalos ¿Cuántos ejemplos se tienen para entrenar y para predecir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  56be85543aeaaa14008c9063   \n",
       "1  56be85543aeaaa14008c9065   \n",
       "2  56be85543aeaaa14008c9066   \n",
       "3  56bf6b0f3aeaaa14008c9601   \n",
       "4  56bf6b0f3aeaaa14008c9602   \n",
       "\n",
       "                                            question               answer  \n",
       "0           When did Beyonce start becoming popular?    in the late 1990s  \n",
       "1  What areas did Beyonce compete in when she was...  singing and dancing  \n",
       "2  When did Beyonce leave Destiny's Child and bec...                 2003  \n",
       "3      In what city and state did Beyonce  grow up?        Houston, Texas  \n",
       "4         In which decade did Beyonce become famous?           late 1990s  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_Q-A.csv')\n",
    "df_train.dropna(inplace=True)\n",
    "df_test = pd.read_csv('test_Q.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de ejemplos de entrenamiento:  86821\n",
      "Cantidad de ejemplos de prueba:  11873\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de ejemplos de entrenamiento: \", df_train.shape[0])\n",
    "print(\"Cantidad de ejemplos de prueba: \", df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86821</td>\n",
       "      <td>86821</td>\n",
       "      <td>86821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>86821</td>\n",
       "      <td>86769</td>\n",
       "      <td>64763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5728dbc5ff5b5019007da844</td>\n",
       "      <td>Where was the torch event held in Vietnam?</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id                                    question  \\\n",
       "count                      86821                                       86821   \n",
       "unique                     86821                                       86769   \n",
       "top     5728dbc5ff5b5019007da844  Where was the torch event held in Vietnam?   \n",
       "freq                           1                                           2   \n",
       "\n",
       "       answer  \n",
       "count   86821  \n",
       "unique  64763  \n",
       "top     three  \n",
       "freq      231  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11873</td>\n",
       "      <td>11873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11873</td>\n",
       "      <td>11864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5732b6b5328d981900602023</td>\n",
       "      <td>What are the main sources of primary law?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id                                   question\n",
       "count                      11873                                      11873\n",
       "unique                     11873                                      11864\n",
       "top     5732b6b5328d981900602023  What are the main sources of primary law?\n",
       "freq                           1                                          2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Realice un preprocesamiento simple a los textos de entrada (preguntas) *tokenizandolos* y pasando a minúsculas para evitar ambiguedad, si desea agregar algun preprocesamiento éxtra ésto se verá reflajado en su nota. A los textos de salida (respuestas) no realice ningún preprocesamiento mas que *tokenizar*, puesto que para la evaluación se solicita retornar los textos en su forma natural. Comente lo realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#preprocesamiento textos de entrada\n",
    "train_questions = [tokenizer.tokenize(sentence.lower()) for sentence in df_train[\"question\"]]\n",
    "test_questions = [word_tokenize(sentence.lower()) for sentence in df_test[\"question\"]]\n",
    "train_answers = [word_tokenize(sentence) for sentence in df_train[\"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'managed', 'the', 'destiny', 's', 'child', 'group']\n",
      "['Mathew', 'Knowles']\n"
     ]
    }
   ],
   "source": [
    "print(train_questions[7])\n",
    "print(train_answers[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             When did Beyonce start becoming popular?\n",
       "1    What areas did Beyonce compete in when she was...\n",
       "2    When did Beyonce leave Destiny's Child and bec...\n",
       "3        In what city and state did Beyonce  grow up? \n",
       "4           In which decade did Beyonce become famous?\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"question\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmas para train y test\n",
    "for q in range(len(train_questions)):\n",
    "    train_questions[q] = [WordNetLemmatizer().lemmatize(w) for w in train_questions[q]]\n",
    "for q in range(len(test_questions)):\n",
    "    test_questions[q] = [WordNetLemmatizer().lemmatize(w) for w in test_questions[q]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['when', 'did', 'beyonce', 'start', 'becoming', 'popular'],\n",
       " ['what',\n",
       "  'area',\n",
       "  'did',\n",
       "  'beyonce',\n",
       "  'compete',\n",
       "  'in',\n",
       "  'when',\n",
       "  'she',\n",
       "  'wa',\n",
       "  'growing',\n",
       "  'up']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Cree un vocabulario para codificar las palabras en las respuestas a generar. Repita el procedimiento para las preguntas. Agrege un símbolo que signifique el fin de la respuesta a generar, así para tener un criterio de cuando una respuesta, valga la redundancia, está efectivamente *respondida* ¿Cuántas palabras tiene el vocabulario de las respuestas y de las preguntas? ¿Ésto podría ser un problema al momento de entrenar la red para que predizca de entre todas ellas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posibles palabras para respuestas : 47423\n"
     ]
    }
   ],
   "source": [
    "vocab_answer = set()\n",
    "for sentence in train_answers:\n",
    "    for word in sentence:\n",
    "        vocab_answer.add(word)\n",
    "vocab_answer = [\"#end\"]+ list(vocab_answer)\n",
    "print('posibles palabras para respuestas :', len(vocab_answer))\n",
    "vocabA_indices = {c: i for i, c in enumerate(vocab_answer)}\n",
    "indices_vocabA = {i: c for i, c in enumerate(vocab_answer)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posibles palabras para preguntas : 35201\n"
     ]
    }
   ],
   "source": [
    "#sameforquestions\n",
    "vocab_question = set()\n",
    "for sentence in train_questions+test_questions:\n",
    "    for word in sentence:\n",
    "        vocab_question.add(word)\n",
    "vocab_question = list(vocab_question)\n",
    "print('posibles palabras para preguntas :', len(vocab_question))\n",
    "vocabQ_indices = {c: i for i, c in enumerate(vocab_question)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Codifique los tokens (palabras) de cada texto que utilizará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output to onehotvector\n",
    "X_answers = [[vocabA_indices[palabra] for palabra in sentence] for sentence in train_answers]\n",
    "Xtrain_question = [[vocabQ_indices[word] for word in sentence] for sentence in train_questions]\n",
    "Xtest_question = [[vocabQ_indices[word] for word in sentence] for sentence in test_questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ésto realice un padding a ambas secuencias, entrada y salida de entrenamiento y a la entrada del conjunto de pruebas. Comente sobre las dimensionalidades finales de los conjuntos de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max largo pregunta: 40\n",
      "Max largo respuesta: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_input_lenght = np.max(list(map(len,train_questions)))\n",
    "max_output_lenght = np.max(list(map(len,train_answers)))+1\n",
    "print(\"Max largo pregunta: {}\\nMax largo respuesta: {}\".format(max_input_lenght, max_output_lenght))\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "Xtrain_question = sequence.pad_sequences(Xtrain_question,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xtest_question = sequence.pad_sequences(Xtest_question,maxlen=max_input_lenght,padding='post',value=0)\n",
    "X_answers = sequence.pad_sequences(X_answers,maxlen=max_output_lenght,padding='post',value=vocabA_indices[\"#end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones Xtrain: (86821, 40)\n",
      "Dimensiones Xtest: (11873, 40)\n",
      "Dimensiones Output: (86821, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensiones Xtrain: {}\".format(Xtrain_question.shape))\n",
    "print(\"Dimensiones Xtest: {}\".format(Xtest_question.shape))\n",
    "print(\"Dimensiones Output: {}\".format(X_answers.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_answers  = X_answers.reshape(X_answers.shape[0],X_answers.shape[1],1)\n",
    "#print(\"Nueva dimensión salida: {}\".format(X_answers.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Defina el modelo encoder-decoder con los módulos de atención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder-Decoder modelo\n",
    "from keras.layers import Input,RepeatVector,TimeDistributed,Dense,Embedding,Flatten,Activation,Permute,Lambda, CuDNNLSTM\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "lenght_output = max_output_lenght\n",
    "hidden_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina el encoder y las compuertas que utilizará: CuDNNGRU,CuDNNLSTM, RNN u otra. Puede utilizar redes bidireccionales en el encoder ¿Esto mejora el resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar con otras compuertas\n",
    "embedding_vector = 64 \n",
    "encoder_input = Input(shape=(max_input_lenght,))\n",
    "embedded = Embedding(input_dim=len(vocabQ_indices),output_dim=embedding_vector,input_length=max_input_lenght)(encoder_input)\n",
    "encoder = CuDNNLSTM(hidden_dim, return_sequences=True)(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina la atención $\\alpha$ que se calculará sobre cada instante de tiempo $T$ computándo su atención en cada instante de tiempo de la decodificación $T'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute T' importance for each step T\n",
    "attention = TimeDistributed(Dense(max_output_lenght, activation='tanh'))(encoder)\n",
    "#softmax a las antenciones sobre todo T\n",
    "attention = Permute([2, 1])(attention)\n",
    "attention = Activation('softmax')(attention) \n",
    "attention = Permute([2, 1])(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplique la atención sobre el encoder y genere las salidas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the attention to encoder\n",
    "def attention_multiply(vects):\n",
    "    encoder, attention = vects\n",
    "    return K.batch_dot(attention,encoder, axes=1)\n",
    "sent_representation = Lambda(attention_multiply)([encoder, attention])\n",
    "decoder = CuDNNLSTM(hidden_dim, return_sequences=True)(sent_representation)\n",
    "probabilities = TimeDistributed(Dense(len(vocab_answer), activation=\"softmax\"))(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina el modelo y descríbalo adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 64)       2252864     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        (None, 40, 128)      99328       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 40, 47)       6063        cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 47, 40)       0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 47, 40)       0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 40, 47)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 47, 128)      0           cu_dnnlstm_1[0][0]               \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)        (None, 47, 128)      132096      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 47, 47423)    6117567     cu_dnnlstm_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 8,607,918\n",
      "Trainable params: 8,607,918\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(encoder_input,probabilities)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 445.00 702.00\" width=\"445pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-698 441,-698 441,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139949801706776 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139949801706776</title>\n",
       "<polygon fill=\"none\" points=\"186,-657.5 186,-693.5 311,-693.5 311,-657.5 186,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-671.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139949801706888 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139949801706888</title>\n",
       "<polygon fill=\"none\" points=\"168,-584.5 168,-620.5 329,-620.5 329,-584.5 168,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-598.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 139949801706776&#45;&gt;139949801706888 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139949801706776-&gt;139949801706888</title>\n",
       "<path d=\"M248.5,-657.4551C248.5,-649.3828 248.5,-639.6764 248.5,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"252.0001,-630.5903 248.5,-620.5904 245.0001,-630.5904 252.0001,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949801707448 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139949801707448</title>\n",
       "<polygon fill=\"none\" points=\"157,-511.5 157,-547.5 340,-547.5 340,-511.5 157,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-525.8\">cu_dnnlstm_1: CuDNNLSTM</text>\n",
       "</g>\n",
       "<!-- 139949801706888&#45;&gt;139949801707448 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139949801706888-&gt;139949801707448</title>\n",
       "<path d=\"M248.5,-584.4551C248.5,-576.3828 248.5,-566.6764 248.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"252.0001,-557.5903 248.5,-547.5904 245.0001,-557.5904 252.0001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613466960 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139949613466960</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 313,-474.5 313,-438.5 0,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156.5\" y=\"-452.8\">time_distributed_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 139949801707448&#45;&gt;139949613466960 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139949801707448-&gt;139949613466960</title>\n",
       "<path d=\"M225.7584,-511.4551C214.1477,-502.2422 199.8542,-490.9006 187.2734,-480.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"189.3079,-478.0644 179.2988,-474.5904 184.9569,-483.5479 189.3079,-478.0644\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613259464 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139949613259464</title>\n",
       "<polygon fill=\"none\" points=\"219,-146.5 219,-182.5 342,-182.5 342,-146.5 219,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-160.8\">lambda_1: Lambda</text>\n",
       "</g>\n",
       "<!-- 139949801707448&#45;&gt;139949613259464 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139949801707448-&gt;139949613259464</title>\n",
       "<path d=\"M282.7014,-511.302C296.7342,-502.184 311.9061,-489.8909 321.5,-475 344.0452,-440.0071 341.5,-425.1268 341.5,-383.5 341.5,-383.5 341.5,-383.5 341.5,-310.5 341.5,-266.1296 317.2171,-219.6293 299.2932,-191.3497\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"302.1323,-189.2958 293.7361,-182.834 296.2701,-193.1214 302.1323,-189.2958\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613466176 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139949613466176</title>\n",
       "<polygon fill=\"none\" points=\"133.5,-365.5 133.5,-401.5 261.5,-401.5 261.5,-365.5 133.5,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-379.8\">permute_1: Permute</text>\n",
       "</g>\n",
       "<!-- 139949613466960&#45;&gt;139949613466176 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139949613466960-&gt;139949613466176</title>\n",
       "<path d=\"M166.6348,-438.4551C171.3657,-430.0319 177.0959,-419.8292 182.3285,-410.5128\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"185.4943,-412.0233 187.3397,-401.5904 179.391,-408.5954 185.4943,-412.0233\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613467240 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139949613467240</title>\n",
       "<polygon fill=\"none\" points=\"144.5,-292.5 144.5,-328.5 292.5,-328.5 292.5,-292.5 144.5,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-306.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 139949613466176&#45;&gt;139949613467240 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139949613466176-&gt;139949613467240</title>\n",
       "<path d=\"M202.691,-365.4551C205.0384,-357.2951 207.8662,-347.4652 210.4772,-338.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"213.8948,-339.1683 213.2959,-328.5904 207.1677,-337.233 213.8948,-339.1683\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613467184 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139949613467184</title>\n",
       "<polygon fill=\"none\" points=\"170.5,-219.5 170.5,-255.5 298.5,-255.5 298.5,-219.5 170.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234.5\" y=\"-233.8\">permute_2: Permute</text>\n",
       "</g>\n",
       "<!-- 139949613467240&#45;&gt;139949613467184 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139949613467240-&gt;139949613467184</title>\n",
       "<path d=\"M222.4551,-292.4551C224.2435,-284.2951 226.398,-274.4652 228.3874,-265.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"231.8128,-266.1079 230.535,-255.5904 224.9751,-264.6091 231.8128,-266.1079\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613467184&#45;&gt;139949613259464 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>139949613467184-&gt;139949613259464</title>\n",
       "<path d=\"M245.8708,-219.4551C251.2338,-210.9441 257.7417,-200.6165 263.6615,-191.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"266.7305,-192.9167 269.1006,-182.5904 260.8082,-189.1848 266.7305,-192.9167\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949613258456 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139949613258456</title>\n",
       "<polygon fill=\"none\" points=\"189,-73.5 189,-109.5 372,-109.5 372,-73.5 189,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-87.8\">cu_dnnlstm_2: CuDNNLSTM</text>\n",
       "</g>\n",
       "<!-- 139949613259464&#45;&gt;139949613258456 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>139949613259464-&gt;139949613258456</title>\n",
       "<path d=\"M280.5,-146.4551C280.5,-138.3828 280.5,-128.6764 280.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"284.0001,-119.5903 280.5,-109.5904 277.0001,-119.5904 284.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139949612170320 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>139949612170320</title>\n",
       "<polygon fill=\"none\" points=\"124,-.5 124,-36.5 437,-36.5 437,-.5 124,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-14.8\">time_distributed_2(dense_2): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 139949613258456&#45;&gt;139949612170320 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>139949613258456-&gt;139949612170320</title>\n",
       "<path d=\"M280.5,-73.4551C280.5,-65.3828 280.5,-55.6764 280.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"284.0001,-46.5903 280.5,-36.5904 277.0001,-46.5904 284.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Entrene el modelo por 10 epochs con el tamaño de batch que estime conveniente. Para ésto deberá redimensionar la salida para que tenga 3 dimensiones debido a la recurrencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_decoded  = np.zeros_like(X_answers[:,:,0])\n",
    "# X_decoded[:, 1:] = X_answers[:,:-1]\n",
    "# X_decoded[:, 0] = vocabA_indices[\"#start\"] #START_CHAR_CODE\n",
    "# X_decoded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_decoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1302560b1ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtrain_question\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_decoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_decoded' is not defined"
     ]
    }
   ],
   "source": [
    "#model.fit([Xtrain_question, X_decoded],X_answers,epochs=10,batch_size=128,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[6016,47423] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_2/Softmax = Softmax[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/time_distributed_2/Softmax_grad/mul_1\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_2/BiasAdd)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1479_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-47e43f0f3156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_question\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/redesneuronales/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/redesneuronales/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/redesneuronales/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/redesneuronales/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/redesneuronales/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/redesneuronales/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6016,47423] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_2/Softmax = Softmax[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/time_distributed_2/Softmax_grad/mul_1\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_2/BiasAdd)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1479_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "X_answers = X_answers.reshape(X_answers.shape[0],X_answers.shape[1],1)\n",
    "X_answers.shape\n",
    "model.fit(Xtrain_question[:5000],X_answers[:5000],epochs=1,batch_size=128,validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
